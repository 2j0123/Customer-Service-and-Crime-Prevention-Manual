{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.command.install_egg_info import to_filename\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "\n",
    "# pretrain_path = r\"C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\WASSUP_EST_FINAL_Team4\\swinv2-tiny-patch4-window8-256-finetuned-emotions\\checkpoint-1509\"\n",
    "pretrain_path = r'C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\swinv2-tiny-patch4-window8-256-finetuned-eurosat\\checkpoint-2516'\n",
    "model_trained = AutoModelForImageClassification.from_pretrained(pretrain_path)\n",
    "test_img_processor = AutoImageProcessor.from_pretrained(pretrain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-classification\", pretrain_path)\n",
    "\n",
    "def img_with_text_results(img):\n",
    "    \n",
    "    #결과\n",
    "    results = str(next(iter(pipe(Image.fromarray(img)))))\n",
    "    \n",
    "    # 폰트 색상 지정\n",
    "    blue = (255, 0, 0)\n",
    "\n",
    "    #한국 폰트\n",
    "    kor_font = ImageFont.truetype('MaruBuri-Light.ttf', 20)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw.text((30,40), results, blue, font=kor_font)\n",
    "\n",
    "    img = np.array(img_pil)\n",
    "    # 폰트 지정\n",
    "    # font = cv2.FONT_HERSHEY_PLAIN\n",
    "    # 이미지에 글자 합성하기\n",
    "    # img = cv2.putText(img, results, (30, 40), font, 2, blue, 1, cv2.LINE_AA)\n",
    "    # img = cv2.putText(img, 'test', (100, 40), font, 2, blue, 1, cv2.LINE_AA)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 캡처 객체 생성\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 프레임들 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "    # 영상 처리 코드 작성\n",
    "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # for img in frame:\n",
    "    #     enc = test_img_processor(img.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "\n",
    "    # enc = test_img_processor(frame, return_tensors=\"pt\")\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model_trained(**enc)\n",
    "    #     logits = outputs.logits\n",
    "    #     predicted_class_idx = logits.argmax(-1).item()\n",
    "        \n",
    "        # predictions.append(model_trained.config.id2label[predicted_class_idx])\n",
    "    # results = next(iter(pipe(frame)))\n",
    "\n",
    "    img = img_with_text_results(frame)\n",
    "\n",
    "    # 영상 출력\n",
    "    \n",
    "    cv2.imshow('Real-time Video', img)\n",
    "\n",
    "    # 'q' 키를 누르면 종\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 객체 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_input(data_src):\n",
    "    vid_file = None\n",
    "    if data_src == 'Sample data':\n",
    "        vid_file = \"data/sample_videos/sample.mp4\"\n",
    "    else:\n",
    "        vid_bytes = st.sidebar.file_uploader(\"Upload a video\", type=['mp4', 'mpv', 'avi'])\n",
    "        if vid_bytes:\n",
    "            vid_file = \"data/uploaded_data/upload.\" + vid_bytes.name.split('.')[-1]\n",
    "            with open(vid_file, 'wb') as out:\n",
    "                out.write(vid_bytes.read())\n",
    "\n",
    "    if vid_file:\n",
    "        cap = cv2.VideoCapture(vid_file)\n",
    "        custom_size = st.sidebar.checkbox(\"Custom frame size\")\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        if custom_size:\n",
    "            width = st.sidebar.number_input(\"Width\", min_value=120, step=20, value=width)\n",
    "            height = st.sidebar.number_input(\"Height\", min_value=120, step=20, value=height)\n",
    "\n",
    "        fps = 0\n",
    "        st1, st2, st3 = st.columns(3)\n",
    "        with st1:\n",
    "            st.markdown(\"## Height\")\n",
    "            st1_text = st.markdown(f\"{height}\")\n",
    "        with st2:\n",
    "            st.markdown(\"## Width\")\n",
    "            st2_text = st.markdown(f\"{width}\")\n",
    "        with st3:\n",
    "            st.markdown(\"## FPS\")\n",
    "            st3_text = st.markdown(f\"{fps}\")\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        output = st.empty()\n",
    "        prev_time = 0\n",
    "        curr_time = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                st.write(\"Can't read frame, stream ended? Exiting ....\")\n",
    "                break\n",
    "            frame = cv2.resize(frame, (width, height))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            output_img = infer_image(frame)\n",
    "            output.image(output_img)\n",
    "            curr_time = time.time()\n",
    "            fps = 1 / (curr_time - prev_time)\n",
    "            prev_time = curr_time\n",
    "            st1_text.markdown(f\"**{height}**\")\n",
    "            st2_text.markdown(f\"**{width}**\")\n",
    "            st3_text.markdown(f\"**{fps:.2f}**\")\n",
    "\n",
    "        cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

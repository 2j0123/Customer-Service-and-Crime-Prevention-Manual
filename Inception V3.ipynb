{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOOKAvkjL91u+x3Qub/PboD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2j0123/WASSUP_EST_FINAL_Team4/blob/SW/Inception%20V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive와 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmQ8Uv9PwmYQ",
        "outputId": "03acc489-4f25-45d7-a836-022f3a8eb9e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 데이터 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/감정따뜻쟁이/train'\n",
        "\n",
        "# 이미지 데이터 생성기 설정\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 이미지 데이터 로드\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Inception-v3 모델 불러오기 (사전 훈련된 가중치 포함)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# 분류기 추가\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# 새로운 모델 정의 (기존의 Inception-v3 모델과 분류기를 결합)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 모든 레이어를 동결하여 기존의 가중치를 고정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(train_generator, epochs=100)\n",
        "\n",
        "# 새로운 이미지 분류 테스트\n",
        "def classify_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, 0)  # 이미지 배치 추가\n",
        "    img_array /= 255.  # 이미지 정규화\n",
        "    predictions = model.predict(img_array)\n",
        "    emotion_labels = ['anger', 'happy', 'sadness', 'panic']\n",
        "    predicted_label = emotion_labels[np.argmax(predictions)]\n",
        "    return predicted_label\n",
        "\n",
        "# 예시: 이미지 분류 테스트\n",
        "test_image_path = '/content/drive/MyDrive/test_image.jpg'  # 테스트할 이미지 파일의 경로\n",
        "predicted_label = classify_image(test_image_path)\n",
        "print('Predicted emotion:', predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B-aNlxj1n56",
        "outputId": "2f991553-9b01-4716-f1e0-5455ca70df3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5369 images belonging to 4 classes.\n",
            "Epoch 1/100\n",
            "168/168 [==============================] - 422s 2s/step - loss: 1.5823 - accuracy: 0.2865\n",
            "Epoch 2/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.3344 - accuracy: 0.3567\n",
            "Epoch 3/100\n",
            "168/168 [==============================] - 410s 2s/step - loss: 1.2984 - accuracy: 0.3848\n",
            "Epoch 4/100\n",
            "168/168 [==============================] - 416s 2s/step - loss: 1.2721 - accuracy: 0.4023\n",
            "Epoch 5/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.2555 - accuracy: 0.4122\n",
            "Epoch 6/100\n",
            "168/168 [==============================] - 410s 2s/step - loss: 1.2367 - accuracy: 0.4390\n",
            "Epoch 7/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 1.2355 - accuracy: 0.4275\n",
            "Epoch 8/100\n",
            "168/168 [==============================] - 413s 2s/step - loss: 1.2172 - accuracy: 0.4515\n",
            "Epoch 9/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 1.2104 - accuracy: 0.4615\n",
            "Epoch 10/100\n",
            "168/168 [==============================] - 411s 2s/step - loss: 1.2072 - accuracy: 0.4614\n",
            "Epoch 11/100\n",
            "168/168 [==============================] - 420s 3s/step - loss: 1.1926 - accuracy: 0.4668\n",
            "Epoch 12/100\n",
            "168/168 [==============================] - 413s 2s/step - loss: 1.1883 - accuracy: 0.4669\n",
            "Epoch 13/100\n",
            "168/168 [==============================] - 413s 2s/step - loss: 1.1807 - accuracy: 0.4640\n",
            "Epoch 14/100\n",
            "168/168 [==============================] - 413s 2s/step - loss: 1.1757 - accuracy: 0.4761\n",
            "Epoch 15/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.1702 - accuracy: 0.4746\n",
            "Epoch 16/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.1597 - accuracy: 0.4844\n",
            "Epoch 17/100\n",
            "168/168 [==============================] - 415s 2s/step - loss: 1.1535 - accuracy: 0.4831\n",
            "Epoch 18/100\n",
            "168/168 [==============================] - 411s 2s/step - loss: 1.1720 - accuracy: 0.4723\n",
            "Epoch 19/100\n",
            "168/168 [==============================] - 417s 2s/step - loss: 1.1475 - accuracy: 0.4934\n",
            "Epoch 20/100\n",
            "168/168 [==============================] - 414s 2s/step - loss: 1.1410 - accuracy: 0.4977\n",
            "Epoch 21/100\n",
            "168/168 [==============================] - 415s 2s/step - loss: 1.1324 - accuracy: 0.5061\n",
            "Epoch 22/100\n",
            "168/168 [==============================] - 411s 2s/step - loss: 1.1286 - accuracy: 0.4982\n",
            "Epoch 23/100\n",
            "168/168 [==============================] - 427s 3s/step - loss: 1.1398 - accuracy: 0.4939\n",
            "Epoch 24/100\n",
            "168/168 [==============================] - 415s 2s/step - loss: 1.1226 - accuracy: 0.5068\n",
            "Epoch 25/100\n",
            "168/168 [==============================] - 415s 2s/step - loss: 1.1285 - accuracy: 0.4941\n",
            "Epoch 26/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 1.1161 - accuracy: 0.5172\n",
            "Epoch 27/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 1.0962 - accuracy: 0.5211\n",
            "Epoch 28/100\n",
            "168/168 [==============================] - 414s 2s/step - loss: 1.1025 - accuracy: 0.5249\n",
            "Epoch 29/100\n",
            "168/168 [==============================] - 418s 2s/step - loss: 1.0981 - accuracy: 0.5150\n",
            "Epoch 30/100\n",
            "168/168 [==============================] - 408s 2s/step - loss: 1.1060 - accuracy: 0.5191\n",
            "Epoch 31/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 1.1010 - accuracy: 0.5265\n",
            "Epoch 32/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.0975 - accuracy: 0.5286\n",
            "Epoch 33/100\n",
            "168/168 [==============================] - 410s 2s/step - loss: 1.0990 - accuracy: 0.5196\n",
            "Epoch 34/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 1.0790 - accuracy: 0.5256\n",
            "Epoch 35/100\n",
            "168/168 [==============================] - 411s 2s/step - loss: 1.0684 - accuracy: 0.5349\n",
            "Epoch 36/100\n",
            "168/168 [==============================] - 409s 2s/step - loss: 1.0747 - accuracy: 0.5318\n",
            "Epoch 37/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 1.0859 - accuracy: 0.5251\n",
            "Epoch 38/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 1.0741 - accuracy: 0.5306\n",
            "Epoch 39/100\n",
            "168/168 [==============================] - 407s 2s/step - loss: 1.0647 - accuracy: 0.5346\n",
            "Epoch 40/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 1.0695 - accuracy: 0.5342\n",
            "Epoch 41/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 1.0580 - accuracy: 0.5411\n",
            "Epoch 42/100\n",
            "168/168 [==============================] - 401s 2s/step - loss: 1.0519 - accuracy: 0.5513\n",
            "Epoch 43/100\n",
            "168/168 [==============================] - 405s 2s/step - loss: 1.0567 - accuracy: 0.5403\n",
            "Epoch 44/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 1.0470 - accuracy: 0.5437\n",
            "Epoch 45/100\n",
            "168/168 [==============================] - 400s 2s/step - loss: 1.0485 - accuracy: 0.5524\n",
            "Epoch 46/100\n",
            "168/168 [==============================] - 405s 2s/step - loss: 1.0479 - accuracy: 0.5485\n",
            "Epoch 47/100\n",
            "168/168 [==============================] - 401s 2s/step - loss: 1.0350 - accuracy: 0.5578\n",
            "Epoch 48/100\n",
            "168/168 [==============================] - 417s 2s/step - loss: 1.0517 - accuracy: 0.5426\n",
            "Epoch 49/100\n",
            "168/168 [==============================] - 411s 2s/step - loss: 1.0233 - accuracy: 0.5612\n",
            "Epoch 50/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 1.0286 - accuracy: 0.5593\n",
            "Epoch 51/100\n",
            "168/168 [==============================] - 407s 2s/step - loss: 1.0485 - accuracy: 0.5485\n",
            "Epoch 52/100\n",
            "168/168 [==============================] - 417s 2s/step - loss: 1.0068 - accuracy: 0.5684\n",
            "Epoch 53/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 1.0172 - accuracy: 0.5649\n",
            "Epoch 54/100\n",
            "168/168 [==============================] - 420s 3s/step - loss: 1.0309 - accuracy: 0.5508\n",
            "Epoch 55/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 1.0026 - accuracy: 0.5783\n",
            "Epoch 56/100\n",
            "168/168 [==============================] - 409s 2s/step - loss: 1.0039 - accuracy: 0.5776\n",
            "Epoch 57/100\n",
            "168/168 [==============================] - 409s 2s/step - loss: 1.0215 - accuracy: 0.5519\n",
            "Epoch 58/100\n",
            "168/168 [==============================] - 407s 2s/step - loss: 0.9994 - accuracy: 0.5750\n",
            "Epoch 59/100\n",
            "168/168 [==============================] - 412s 2s/step - loss: 0.9943 - accuracy: 0.5686\n",
            "Epoch 60/100\n",
            "168/168 [==============================] - 413s 2s/step - loss: 0.9978 - accuracy: 0.5763\n",
            "Epoch 61/100\n",
            "168/168 [==============================] - 409s 2s/step - loss: 0.9912 - accuracy: 0.5850\n",
            "Epoch 62/100\n",
            "168/168 [==============================] - 410s 2s/step - loss: 0.9843 - accuracy: 0.5815\n",
            "Epoch 63/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 0.9951 - accuracy: 0.5742\n",
            "Epoch 64/100\n",
            "168/168 [==============================] - 408s 2s/step - loss: 0.9814 - accuracy: 0.5839\n",
            "Epoch 65/100\n",
            "168/168 [==============================] - 405s 2s/step - loss: 0.9803 - accuracy: 0.5899\n",
            "Epoch 66/100\n",
            "168/168 [==============================] - 404s 2s/step - loss: 0.9719 - accuracy: 0.5882\n",
            "Epoch 67/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 0.9825 - accuracy: 0.5737\n",
            "Epoch 68/100\n",
            "168/168 [==============================] - 408s 2s/step - loss: 0.9885 - accuracy: 0.5835\n",
            "Epoch 69/100\n",
            "168/168 [==============================] - 419s 2s/step - loss: 0.9923 - accuracy: 0.5699\n",
            "Epoch 70/100\n",
            "168/168 [==============================] - 407s 2s/step - loss: 0.9730 - accuracy: 0.5787\n",
            "Epoch 71/100\n",
            "168/168 [==============================] - 406s 2s/step - loss: 0.9619 - accuracy: 0.5910\n",
            "Epoch 72/100\n",
            "168/168 [==============================] - 405s 2s/step - loss: 0.9730 - accuracy: 0.5871\n",
            "Epoch 73/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 0.9726 - accuracy: 0.5873\n",
            "Epoch 74/100\n",
            "168/168 [==============================] - 398s 2s/step - loss: 0.9472 - accuracy: 0.6023\n",
            "Epoch 75/100\n",
            "168/168 [==============================] - 394s 2s/step - loss: 0.9704 - accuracy: 0.5867\n",
            "Epoch 76/100\n",
            "168/168 [==============================] - 400s 2s/step - loss: 0.9484 - accuracy: 0.6048\n",
            "Epoch 77/100\n",
            "168/168 [==============================] - 395s 2s/step - loss: 0.9787 - accuracy: 0.5871\n",
            "Epoch 78/100\n",
            "168/168 [==============================] - 403s 2s/step - loss: 0.9460 - accuracy: 0.6016\n",
            "Epoch 79/100\n",
            "168/168 [==============================] - 396s 2s/step - loss: 0.9398 - accuracy: 0.5997\n",
            "Epoch 80/100\n",
            "168/168 [==============================] - 395s 2s/step - loss: 0.9322 - accuracy: 0.6064\n",
            "Epoch 81/100\n",
            "168/168 [==============================] - 396s 2s/step - loss: 0.9466 - accuracy: 0.6044\n",
            "Epoch 82/100\n",
            "168/168 [==============================] - 393s 2s/step - loss: 0.9386 - accuracy: 0.6040\n",
            "Epoch 83/100\n",
            "168/168 [==============================] - 386s 2s/step - loss: 0.9323 - accuracy: 0.6182\n",
            "Epoch 84/100\n",
            "168/168 [==============================] - 389s 2s/step - loss: 0.9198 - accuracy: 0.6189\n",
            "Epoch 85/100\n",
            "168/168 [==============================] - 387s 2s/step - loss: 0.9241 - accuracy: 0.6204\n",
            "Epoch 86/100\n",
            "168/168 [==============================] - 396s 2s/step - loss: 0.9392 - accuracy: 0.6092\n",
            "Epoch 87/100\n",
            "168/168 [==============================] - 397s 2s/step - loss: 0.9227 - accuracy: 0.6180\n",
            "Epoch 88/100\n",
            "168/168 [==============================] - 384s 2s/step - loss: 0.9247 - accuracy: 0.6115\n",
            "Epoch 89/100\n",
            "168/168 [==============================] - 386s 2s/step - loss: 0.9324 - accuracy: 0.6038\n",
            "Epoch 90/100\n",
            "168/168 [==============================] - 385s 2s/step - loss: 0.9378 - accuracy: 0.6111\n",
            "Epoch 91/100\n",
            "168/168 [==============================] - 384s 2s/step - loss: 0.9347 - accuracy: 0.6085\n",
            "Epoch 92/100\n",
            "168/168 [==============================] - 378s 2s/step - loss: 0.9257 - accuracy: 0.6070\n",
            "Epoch 93/100\n",
            "168/168 [==============================] - 392s 2s/step - loss: 0.9253 - accuracy: 0.6238\n",
            "Epoch 94/100\n",
            "168/168 [==============================] - 393s 2s/step - loss: 0.9326 - accuracy: 0.6057\n",
            "Epoch 95/100\n",
            "168/168 [==============================] - 388s 2s/step - loss: 0.9112 - accuracy: 0.6234\n",
            "Epoch 96/100\n",
            "168/168 [==============================] - 396s 2s/step - loss: 0.9052 - accuracy: 0.6264\n",
            "Epoch 97/100\n",
            "168/168 [==============================] - 401s 2s/step - loss: 0.9143 - accuracy: 0.6167\n",
            "Epoch 98/100\n",
            "168/168 [==============================] - 394s 2s/step - loss: 0.9107 - accuracy: 0.6212\n",
            "Epoch 99/100\n",
            "168/168 [==============================] - 395s 2s/step - loss: 0.8839 - accuracy: 0.6297\n",
            "Epoch 100/100\n",
            "168/168 [==============================] - 397s 2s/step - loss: 0.9111 - accuracy: 0.6187\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted emotion: panic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab에서 파일 업로드하기 위한 라이브러리 import\n",
        "from google.colab import files\n",
        "\n",
        "# 이미지 분류 함수 정의\n",
        "def classify_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(299, 299))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, 0)  # 이미지 배치 추가\n",
        "    img_array /= 255.  # 이미지 정규화\n",
        "    predictions = model.predict(img_array)\n",
        "    emotion_labels = ['anger', 'happy', 'sadness', 'panic']\n",
        "    predicted_label = emotion_labels[np.argmax(predictions)]\n",
        "    return predicted_label\n",
        "\n",
        "# 사용자가 업로드한 파일을 받아서 이미지 분류하는 함수 정의\n",
        "def classify_uploaded_images():\n",
        "    uploaded = files.upload()  # 사용자로부터 파일 업로드 받기\n",
        "    for filename in uploaded.keys():\n",
        "        image_path = '/content/' + filename\n",
        "        predicted_label = classify_image(image_path)\n",
        "        print(f'{filename}의 감정은 {predicted_label}입니다.')\n",
        "\n",
        "# 사용자가 원하는 만큼 사진 또는 영상을 업로드하고 분류\n",
        "while True:\n",
        "    classify_uploaded_images()\n",
        "    continue_upload = input(\"더 업로드하시겠습니까? (yes/no): \")\n",
        "    if continue_upload.lower() != 'yes':\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "Dy7k21d55mjy",
        "outputId": "304ad96f-75c5-450e-c7fe-883262129e9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e31dc15d-1194-45f9-bad3-ba3986370258\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e31dc15d-1194-45f9-bad3-ba3986370258\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 0pnnbde1bec084d09efe5011eacbd99aa3ef8ad004d0d15ae3381adc39bd9j0qo.jpg to 0pnnbde1bec084d09efe5011eacbd99aa3ef8ad004d0d15ae3381adc39bd9j0qo.jpg\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "0pnnbde1bec084d09efe5011eacbd99aa3ef8ad004d0d15ae3381adc39bd9j0qo.jpg의 감정은 happy입니다.\n",
            "더 업로드하시겠습니까? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-141c946b-e816-42f9-9854-c790eac4732f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-141c946b-e816-42f9-9854-c790eac4732f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving okss9bb8ceb2bbef180fbee6d54ecefdd331d67f7fe3bb167c03ddeb5d890go7q.jpg to okss9bb8ceb2bbef180fbee6d54ecefdd331d67f7fe3bb167c03ddeb5d890go7q.jpg\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "okss9bb8ceb2bbef180fbee6d54ecefdd331d67f7fe3bb167c03ddeb5d890go7q.jpg의 감정은 happy입니다.\n",
            "더 업로드하시겠습니까? (yes/no): no\n"
          ]
        }
      ]
    }
  ]
}
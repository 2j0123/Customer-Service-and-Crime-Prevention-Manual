import streamlit as st
import numpy as np
import cv2
from PIL import Image
import time
import os
# ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ
import config              
from select_git import run_select
from utils import vid_with_label_1stg, vid_with_label_2stage

def stream_display(response, placeholder):        # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ì‘ë‹µê°ì²´, í…ìŠ¤íŠ¸ í‘œì‹œí•  ìœ„ì¹˜)
    text = ''
    for chunk in response:
        if parts := chunk.parts:
            if parts_text := parts[0].text:
                text += parts_text
                placeholder.write(text + "â–Œ")
    return text

def init_messages() -> None:                # init_message í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    st.session_state.messages = []

def undo() -> None:                        # undo í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì œê±°
    st.session_state.messages.pop()

def set_generate(state=True):                # ê¸°ë³¸ê°’ì„ Trueë¡œ ì„¤ì •
    st.session_state.generate = state

st.title("ğŸ’¬ Emotion detector")            # Streamlit ì œëª©ê³¼ ìº¡ì…˜
st.caption("ğŸš€ A streamlit emotion detector by custom model")

# confidence = float(st.sidebar.slider(
#     "Select Model Confidence", 25, 40, 60, 80, 100 )) / 100

confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100        # ì‚¬ì´ë“œ ë°”ì— ëª¨ë¸ ì‹ ë¢°ë„ & ëª¨ë¸ ì„ íƒ ë©”ë‰´
model_selection = st.sidebar.selectbox("Select Model", ["Model 1 (1stg)", "Model 2 (5emo_1stg)", "Model 3 (2stg)", "Model 4 (5emo_2stg)"])

def main():            #camera_activeí‚¤ê°€ sesstion_state ê°’ì— ì—†ìœ¼ë©´ Trueë¡œ ì„¤ì •
    if 'camera_active' not in st.session_state:
        st.session_state.camera_active = True
        
    set_generate()  # generate í˜¸ì¶œí•´ì„œ íƒ€ì´í‹€ & ìº¡ì…˜ ì„¤ì •, Run ì²´í¬ë°•ìŠ¤ ì¶”ê°€
    run = st.checkbox('Run')
    cap = cv2.VideoCapture(0)    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    FRAME_WINDOW = st.image([])    # ì´ë¯¸ì§€ í”„ë ˆì„ì„ í‘œì‹œí•  ìœ„ì¹˜

    start_time = None
    emotion_detected = None
    dark_warning = st.empty()  # í™”ë©´ì´ ì–´ë‘ìš¸ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ í‘œì‹œí•  ìë¦¬

    last_frame = None

    try:
        while run and st.session_state.get("camera_active", True):        # Run ì„ íƒëœ ê²½ìš° camera_activeê°€ Trueì¸ ë™ì•ˆ ì‹¤í–‰
            success, frame = cap.read()
            frame = cv2.resize(frame, (640, 480))
            
            if success:                                                # í”„ë ˆì„ì„ last_frameì— ì €ì¥ & GrayScaleë¡œ ë³€í™˜ -> ë°ê¸° ê³„ì‚°
                last_frame = frame.copy()
                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   #GrayScale 
                brightness = np.mean(gray_frame)
                
                if brightness < 30:  # ë°ê¸° 30 ë¯¸ë§Œì´ë©´ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
                    dark_warning.warning("ë„ˆë¬´ ì–´ë‘¡ìŠµë‹ˆë‹¤. í™”ë©´ì´ ê°€ë ¤ì§„ê±´ ì•„ë‹Œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    continue
                else:
                    dark_warning.empty()

                # ëª¨ë¸ë³„ë¡œ ì ì ˆí•œ í•¨ìˆ˜ í˜¸ì¶œ -> ì´ë¯¸ì§€ & ë ˆì´ë¸” í• ë‹¹
                if model_selection == "Model 1 (1stg)":
                    img, label = vid_with_label_1stg(frame, confidence, config.YOLO_CUSTOM)
                elif model_selection == "Model 2 (5emo_1stg)" :
                    img, label = vid_with_label_1stg(frame, confidence, config.YOLO_5EMO)
                elif model_selection == "Model 3 (2stg)" :
                    img, label = vid_with_label_2stage(frame, confidence, config.SWINV2)
                elif model_selection == "Model 4 (5emo_2stg)" :
                    img, label = vid_with_label_2stage(frame, confidence, config.SWINV2_5EMO)

                # ê°ì§€ëœ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜í•˜ì—¬ í™”ë©´ì— í‘œì‹œ
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                FRAME_WINDOW.image(img)

                # Happyê°€ ì•„ë‹Œ ê²½ìš°ê°€ 1ì´ˆ ì´ìƒ ê°ì§€ë˜ë©´ ê°ì •ì„ í™”ë©´ì— í‘œì‹œ & ì¹´ë©”ë¼ ì¢…ë£Œ / ê·¸ë ‡ì§€ì•Šì„ê²½ìš° ê°ì • ì´ˆê¸°í™”
                if label and label != 'Happy':
                    if emotion_detected is None:
                        emotion_detected = label
                        start_time = time.time()
                    elif emotion_detected == label and time.time() - start_time >= 1:
                        st.write(f"{label} detected for 1 s")
                        st.session_state.camera_active = False
                        break
                else:
                    emotion_detected = None
                    start_time = None    
            else:                #í”„ë ˆì„ì„ ì½ì§€ ëª»í•œê²½ìš° ì¹´ë©”ë¼ í•´ì œ & ë£¨í”„ ì¢…ë£Œ
                cap.release()
                break

        # ë§ˆì§€ë§‰ í”„ë ˆì„ì´ ìˆìœ¼ë©´ RGBë¡œ ë³€í™˜í•˜ì—¬ í™”ë©´ì— í‘œì‹œ
        if last_frame is not None:
            last_frame_rgb = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)
            FRAME_WINDOW.image(last_frame_rgb)

        cap.release()        # ì¹´ë©”ë¼ë¥¼ í•´ì œí•˜ê³  ê°ì§€ëœ ê°ì •ì„ í™”ë©´ì— í‘œì‹œ -> run_select í•¨ìˆ˜ í˜¸ì¶œ
        
        st.write(f'Detected emotion: {emotion_detected}')
        run_select()

    except Exception as e:        # ì˜ˆì™¸ ë°œìƒì‹œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
        st.error(f"Error loading video: {str(e)}")

# scriptê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main í•¨ìˆ˜ í˜¸ì¶œ
if __name__ == "__main__":
    main()

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.command.install_egg_info import to_filename\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "\n",
    "# pretrain_path = r\"C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\WASSUP_EST_FINAL_Team4\\swinv2-tiny-patch4-window8-256-finetuned-emotions\\checkpoint-1509\"\n",
    "pretrain_path = r'C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\swinv2-tiny-patch4-window8-256-finetuned-eurosat\\checkpoint-2516'\n",
    "model_trained = AutoModelForImageClassification.from_pretrained(pretrain_path)\n",
    "test_img_processor = AutoImageProcessor.from_pretrained(pretrain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-classification\", pretrain_path)\n",
    "\n",
    "def img_with_text_results(img):\n",
    "    \n",
    "    #결과\n",
    "    results = str(next(iter(pipe(Image.fromarray(img)))))\n",
    "    \n",
    "    # 폰트 색상 지정\n",
    "    blue = (255, 0, 0)\n",
    "\n",
    "    #한국 폰트\n",
    "    kor_font = ImageFont.truetype('MaruBuri-Light.ttf', 20)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw.text((30,40), results, blue, font=kor_font)\n",
    "\n",
    "    img = np.array(img_pil)\n",
    "    # 폰트 지정\n",
    "    # font = cv2.FONT_HERSHEY_PLAIN\n",
    "    # 이미지에 글자 합성하기\n",
    "    # img = cv2.putText(img, results, (30, 40), font, 2, blue, 1, cv2.LINE_AA)\n",
    "    # img = cv2.putText(img, 'test', (100, 40), font, 2, blue, 1, cv2.LINE_AA)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 캡처 객체 생성\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 프레임들 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "    # 영상 처리 코드 작성\n",
    "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # for img in frame:\n",
    "    #     enc = test_img_processor(img.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "\n",
    "    # enc = test_img_processor(frame, return_tensors=\"pt\")\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model_trained(**enc)\n",
    "    #     logits = outputs.logits\n",
    "    #     predicted_class_idx = logits.argmax(-1).item()\n",
    "        \n",
    "        # predictions.append(model_trained.config.id2label[predicted_class_idx])\n",
    "    # results = next(iter(pipe(frame)))\n",
    "\n",
    "    img = img_with_text_results(frame)\n",
    "\n",
    "    # 영상 출력\n",
    "    \n",
    "    cv2.imshow('Real-time Video', img)\n",
    "\n",
    "    # 'q' 키를 누르면 종\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 객체 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def video_input(data_src):\n",
    "#     vid_file = None\n",
    "#     if data_src == 'Sample data':\n",
    "#         vid_file = \"data/sample_videos/sample.mp4\"\n",
    "#     else:\n",
    "#         vid_bytes = st.sidebar.file_uploader(\"Upload a video\", type=['mp4', 'mpv', 'avi'])\n",
    "#         if vid_bytes:\n",
    "#             vid_file = \"data/uploaded_data/upload.\" + vid_bytes.name.split('.')[-1]\n",
    "#             with open(vid_file, 'wb') as out:\n",
    "#                 out.write(vid_bytes.read())\n",
    "\n",
    "#     if vid_file:\n",
    "#         cap = cv2.VideoCapture(vid_file)\n",
    "#         custom_size = st.sidebar.checkbox(\"Custom frame size\")\n",
    "#         width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#         if custom_size:\n",
    "#             width = st.sidebar.number_input(\"Width\", min_value=120, step=20, value=width)\n",
    "#             height = st.sidebar.number_input(\"Height\", min_value=120, step=20, value=height)\n",
    "\n",
    "#         fps = 0\n",
    "#         st1, st2, st3 = st.columns(3)\n",
    "#         with st1:\n",
    "#             st.markdown(\"## Height\")\n",
    "#             st1_text = st.markdown(f\"{height}\")\n",
    "#         with st2:\n",
    "#             st.markdown(\"## Width\")\n",
    "#             st2_text = st.markdown(f\"{width}\")\n",
    "#         with st3:\n",
    "#             st.markdown(\"## FPS\")\n",
    "#             st3_text = st.markdown(f\"{fps}\")\n",
    "\n",
    "#         st.markdown(\"---\")\n",
    "#         output = st.empty()\n",
    "#         prev_time = 0\n",
    "#         curr_time = 0\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 st.write(\"Can't read frame, stream ended? Exiting ....\")\n",
    "#                 break\n",
    "#             frame = cv2.resize(frame, (width, height))\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             output_img = infer_image(frame)\n",
    "#             output.image(output_img)\n",
    "#             curr_time = time.time()\n",
    "#             fps = 1 / (curr_time - prev_time)\n",
    "#             prev_time = curr_time\n",
    "#             st1_text.markdown(f\"**{height}**\")\n",
    "#             st2_text.markdown(f\"**{width}**\")\n",
    "#             st3_text.markdown(f\"**{fps:.2f}**\")\n",
    "\n",
    "#         cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_path = r\"C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\WASSUP_EST_FINAL_Team4\\best_yolov8_model.pt\"\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file is not a valid HDF5 file or is corrupted.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Verify that the file is an HDF5 file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file is a valid HDF5 file.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\my_env_py311\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\my_env_py311\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = r\"C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\WASSUP_EST_FINAL_Team4\\model.h5\"\n",
    "# model = load_model(r\"C:\\Users\\User\\Desktop\\Code\\Github\\Final_project\\WASSUP_EST_FINAL_Team4\\model.h5\")\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"File not found at the specified path.\")\n",
    "else:\n",
    "    # Verify that the file is an HDF5 file\n",
    "    try:\n",
    "        with h5py.File(model_path, 'r') as f:\n",
    "            print(\"The file is a valid HDF5 file.\")\n",
    "    except OSError:\n",
    "        print(\"The file is not a valid HDF5 file or is corrupted.\")\n",
    "        raise\n",
    "\n",
    "    # Load the model\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

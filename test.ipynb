{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 90.2ms\n",
      "Speed: 3.0ms preprocess, 90.2ms inference, 911.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 {2: 'panic'}, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 46.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Panic\n",
      "\n",
      "0: 480x640 1 {2: 'panic'}, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Panic\n",
      "\n",
      "0: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.7ms\n",
      "Speed: 0.5ms preprocess, 5.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 {2: 'panic'}, 6.0ms\n",
      "Speed: 0.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Panic\n",
      "\n",
      "0: 480x640 1 {2: 'panic'}, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Panic\n",
      "\n",
      "0: 480x640 1 {1: 'happy'}, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Happy\n",
      "\n",
      "0: 480x640 1 {2: 'panic'}, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Panic\n",
      "\n",
      "0: 480x640 (no detections), 6.0ms\n",
      "Speed: 0.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 6.0ms\n",
      "Speed: 0.5ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 11.1ms\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "def vid_with_label_1stg(img):\n",
    "\n",
    "    \n",
    "    model_path = \"models\\yolo_custom_model.pt\"\n",
    "    model = YOLO(model_path)\n",
    "    # img = cv2.resize(img, (720, int(720 * (9 / 16))))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "      res = model.track(img, conf = 0.5, persist = True, device = 'cuda' )\n",
    "    else:\n",
    "      res = model.track(img, conf = 0.5, persist = True)\n",
    "    \n",
    "    res_plotted = res[0].plot()\n",
    "    id2label = {\n",
    "    '0' : 'Anger',\n",
    "    '1' : 'Happy',\n",
    "    '2' : 'Panic',\n",
    "    '3' : 'Sadness'\n",
    "    }\n",
    "    # yolo 에서 가져온 값들 따로 처리해보기\n",
    "    try:\n",
    "        # start_point , end_point = np.array_split(res[0].boxes.xyxy.cpu().numpy().tolist()[0],2)\n",
    "        # score = str(round(res[0].boxes.conf.cpu().numpy().tolist()[0]*100,2))+ '%'\n",
    "   \n",
    "        label = id2label[str(int(res[0].boxes.cls.cpu().numpy().tolist()[0]))]\n",
    "        return res_plotted, label\n",
    "        # results_str = label + ':'+ score\n",
    "    except Exception as e:\n",
    "       return res_plotted, None\n",
    "    \n",
    "# 비디오 캡처 객체 생성\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 프레임들 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img, label = vid_with_label_1stg(frame)\n",
    "    \n",
    "    if label is not None:\n",
    "        print(label)\n",
    "\n",
    "    # 영상 출력\n",
    "    \n",
    "    cv2.imshow('Real-time Video', img)\n",
    "\n",
    "    # 'q' 키를 누르면 종\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 객체 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "happy\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.5ms\n",
      "Speed: 0.5ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 10.5ms\n",
      "Speed: 1.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "sadness\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "sadness\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "sadness\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "panic\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 13.5ms\n",
      "Speed: 1.0ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 15.6ms\n",
      "Speed: 1.0ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "happy\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 28.8ms\n",
      "Speed: 1.0ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n",
      "\n",
      "0: 480x640 1 {0: 'person'}, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "anger\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import config_test\n",
    "\n",
    "def vid_with_label_2stage(img):\n",
    "\n",
    "    \n",
    "    yolo_path = \"models/yolo_face_detection.pt\"\n",
    "    model = YOLO(yolo_path)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "      res = model.track(img, conf = 0.5, persist = True, device = 'cuda' )\n",
    "    else:\n",
    "      res = model.track(img, conf = 0.5, persist = True)\n",
    "\n",
    "    if res is not None:\n",
    "      try:\n",
    "        # yolo 에서 가져온 값들 따로 처리해보기\n",
    "        start_point , end_point = np.array_split(res[0].boxes.xyxy.cpu().numpy().tolist()[0],2)\n",
    "        # 이미지를 슬라이스 하기\n",
    "        roi = img[int(start_point[1]):int(end_point[1]), int(start_point[0]):int(end_point[0])]\n",
    "\n",
    "        # swin 모델 불러오기\n",
    "        swin_path = config_test.SWINV2\n",
    "        pipe = pipeline(\"image-classification\", swin_path)\n",
    "\n",
    "        kr_to_en = { '분노'    : 'anger',\n",
    "                    '기쁨'    : 'happy',\n",
    "                    '당황'    : 'panic',\n",
    "                    '슬픔'    : 'sadness'             \n",
    "                    }\n",
    "        \n",
    "        \n",
    "        #결과\n",
    "        results = next(iter(pipe(Image.fromarray(roi))))\n",
    "        results_str = kr_to_en[results['label']] + \": \" + str(round(results['score']*100, 2)) + '%'\n",
    "        #cv2 로 박스랑 글자 생성\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        blue  = (255, 0, 0)\n",
    "        red = (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(img, (int(start_point[0]), int(start_point[1])), \n",
    "                  (int(end_point[0]), int(end_point[1])), blue, 3)\n",
    "\n",
    "        cv2.putText(img, results_str, (int(start_point[0]), int(start_point[1])) , font, 1, red, 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        return img, kr_to_en[results['label']]\n",
    "      except Exception as e :\n",
    "         return img, None\n",
    "    else:\n",
    "      return img, None\n",
    "    \n",
    "  # 비디오 캡처 객체 생성\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 프레임들 읽기\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img, label = vid_with_label_2stage(frame)\n",
    "    \n",
    "    if label is not None:\n",
    "        print(label)\n",
    "\n",
    "    # 영상 출력\n",
    "    \n",
    "    cv2.imshow('Real-time Video', img)\n",
    "\n",
    "    # 'q' 키를 누르면 종\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 객체 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

import streamlit as st
import numpy as np
import cv2
from PIL import Image
import tensorflow as tf
import torch
from ultralytics import YOLO
import time
import os
# ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ
import config              
from select_git import run_select
from utils import vid_with_label_1stg, vid_with_label_2stage

def stream_display(response, placeholder):        # ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ì‘ë‹µê°ì²´, í…ìŠ¤íŠ¸ í‘œì‹œí•  ìœ„ì¹˜)
    text = ''
    for chunk in response:
        if parts := chunk.parts:
            if parts_text := parts[0].text:
                text += parts_text
                placeholder.write(text + "â–Œ")
    return text

def init_messages() -> None:                # init_message í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    st.session_state.messages = []

def undo() -> None:                        # undo í•¨ìˆ˜ë¡œ ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì œê±°
    st.session_state.messages.pop()

def set_generate(state=True):                # ê¸°ë³¸ê°’ì„ Trueë¡œ ì„¤ì •
    st.session_state.generate = state

st.title("ğŸ’¬ Emotion detector")            # Streamlit ì œëª©ê³¼ ìº¡ì…˜
st.caption("ğŸš€ A streamlit emotion detector by custom model")

# confidence = float(st.sidebar.slider(
#     "Select Model Confidence", 25, 40, 60, 80, 100 )) / 100

confidence = float(st.sidebar.slider("Select Model Confidence", 25, 100, 40)) / 100        # ì‚¬ì´ë“œ ë°”ì— ëª¨ë¸ ì‹ ë¢°ë„ & ëª¨ë¸ ì„ íƒ ë©”ë‰´
model_selection = st.sidebar.selectbox("Select Model", ["Model 1 (1stg)", "Model 2 (5emo_1stg)", "Model 3 (2stg)", "Model 4 (5emo_2stg)"])

def main():        
    set_generate()  # generate í˜¸ì¶œí•´ì„œ st.session_state.generate ì„¤ì •
    run = st.checkbox('Run')    # Run ì²´í¬ë°•ìŠ¤ ìƒì„± & ì„ íƒ ì—¬ë¶€ë¥¼ runì— ì €ì¥
    cap = cv2.VideoCapture(0)    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    FRAME_WINDOW = st.image([])    # ì´ë¯¸ì§€ í”„ë ˆì„ì„ í‘œì‹œí•  ìœ„ì¹˜
    start_time = None
    emotion_detected = None
    
    try:
        while run:        # Run ì„ íƒëœ ê²½ìš° 
            success, frame = cap.read()
            frame = cv2.resize(frame, (640, 480))

            if success:
            # ëª¨ë¸ë³„ë¡œ ì ì ˆí•œ í•¨ìˆ˜ í˜¸ì¶œ -> ì´ë¯¸ì§€ & ë ˆì´ë¸” í• ë‹¹
                if model_selection == "Model 1 (1stg)":
                    img, label = vid_with_label_1stg(frame, confidence, config.YOLO_CUSTOM)
                elif model_selection == "Model 2 (5emo_1stg)" :
                    img, label = vid_with_label_1stg(frame, confidence, config.YOLO_5EMO)
                elif model_selection == "Model 3 (2stg)" :
                    img, label = vid_with_label_2stage(frame, confidence, config.SWINV2)
                elif model_selection == "Model 4 (5emo_2stg)" :
                    img, label = vid_with_label_2stage(frame, confidence, config.SWINV2_BOXED)

                    # Happyê°€ ì•„ë‹Œ ê²½ìš°ê°€ 3ì´ˆ ì´ìƒ ê°ì§€ë˜ë©´ ê°ì •ì„ í™”ë©´ì— í‘œì‹œ & ì¹´ë©”ë¼ ì¢…ë£Œ / ê·¸ë ‡ì§€ì•Šì„ê²½ìš° ê°ì • ì´ˆê¸°í™”
                if label and label != 'Happy':
                    if emotion_detected is None:
                        emotion_detected = label
                        start_time = time.time()
                    elif emotion_detected == label and time.time() - start_time >= 2:
                        st.write(f"{label} detected for 2 s")
                        run = False
                        os.system("streamlit run select_git.py")
                        break
                else:
                    emotion_detected = None
                    start_time = None    
            else:                #í”„ë ˆì„ì„ ì½ì§€ ëª»í•œê²½ìš° ì¹´ë©”ë¼ í•´ì œ & ë£¨í”„ ì¢…ë£Œ
                cap.release()
                break
        else:
            st.write('Stopped')    
    except Exception as e:        # ì˜ˆì™¸ ë°œìƒì‹œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
        st.error(f"Error loading video: {str(e)}")

# scriptê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œ main í•¨ìˆ˜ í˜¸ì¶œ
if __name__ == "__main__":
    main()
